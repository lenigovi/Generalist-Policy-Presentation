{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f31915c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480f8c5",
   "metadata": {},
   "source": [
    "# Introduction to Generalist Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ccf061",
   "metadata": {},
   "source": [
    "## Understanding Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec8018a",
   "metadata": {},
   "source": [
    "Policy $(\\pi)$ is a model that maps an agentâ€™s actions to states. The policy map gives the probability of taking action $A$ when in state $S$.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div>\n",
    "<img src=\"img/policy2.png\" width=\"380\" style=\"margin-right: 60px;\"/> <img src=\"img/policy3.png\" width=\"380\" style=\"margin-right: 60px;\"/> <img src=\"img/feedbackloop.png\" width=\"370\"/> \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc60212",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0a5e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c2cb8b",
   "metadata": {},
   "source": [
    "<img src=\"img/transformer.png\" width=\"740\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfcfa5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14459981",
   "metadata": {},
   "source": [
    "<img src=\"img/architecture.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a23514-a325-49fa-a398-e6da79bd5fd0",
   "metadata": {},
   "source": [
    "## Understanding Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fe91e65-40ad-42c0-8af9-3d369ae41d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Put': 0, 'cube': 1, 'on': 2, 'table': 3, 'the': 5}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Put the cube on the table'\n",
    "\n",
    "dc = {s:i for i,s \n",
    "      in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "\n",
    "print(dc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cb28c-eaab-4fa8-9b32-ef8c1f596161",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "871323e2-3fc6-4af7-bbb0-359a9cee9ebd",
   "metadata": {},
   "source": [
    "We use the dictionary to assign an integer index to each word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed7064f-f45d-435f-8ad8-ddfb0a24efbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 1, 2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor(\n",
    "    [dc[s] for s in sentence.replace(',', '').split()]\n",
    ")\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fb4e87-d7be-4580-b782-b1892b04e162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035],\n",
      "        [ 0.2692, -0.0770, -1.0205],\n",
      "        [-0.5880,  0.3486,  0.6603],\n",
      "        [-0.2196, -0.3792,  0.7671],\n",
      "        [ 0.2692, -0.0770, -1.0205],\n",
      "        [-1.1925,  0.6984, -1.4097]])\n",
      "torch.Size([6, 3])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50_000\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(vocab_size, 3)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "\n",
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26ba649-b9ba-449b-a2f6-e95d79688215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "d = embedded_sentence.shape[1]\n",
    "d_q, d_k, d_v = 2, 2, 4\n",
    "W_query = torch.nn.Parameter(torch.rand(d, d_q))\n",
    "W_key = torch.nn.Parameter(torch.rand(d, d_k))\n",
    "W_value = torch.nn.Parameter(torch.rand(d, d_v))\n",
    "\n",
    "\n",
    "x_2 = embedded_sentence[1]\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "\n",
    "print(query_2.shape)\n",
    "print(key_2.shape)\n",
    "print(value_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3f4896b-f954-43e7-af97-f18780a01458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "keys = embedded_sentence @ W_key\n",
    "values = embedded_sentence @ W_value\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19a71206-b606-46df-89cf-8438e2b2b1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5869, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "omega_24 = query_2.dot(keys[4])\n",
    "print(omega_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31edba58-fbda-4b89-af3f-eaa9bb5c7549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2432,  0.5869, -0.5191, -0.1851,  0.5869,  0.4730],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2 @ keys.T\n",
    "print(omega_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8be525-41b2-4cb3-a521-e90c252064ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d17b45",
   "metadata": {},
   "source": [
    "# Understanding Query, Key, Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d3aadf",
   "metadata": {},
   "source": [
    "<img src=\"img/attention.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad55a37a-8fd0-4ec8-9cce-8810f579ec1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Softmax Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b05199",
   "metadata": {},
   "source": [
    "<img src=\"img/softmax.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e370dad-6d32-4b1d-9ab8-dfd90fdea3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.903, 0.05, 0.011, 0.017]\n"
     ]
    }
   ],
   "source": [
    "def softmax(input_vector):\n",
    "    # Calculate the exponent of each element in the input vector\n",
    "    exponents = [exp(i) for i in input_vector]\n",
    "\n",
    "    # Calculate the sum of the exponents\n",
    "    sum_of_exponents = sum(exponents)\n",
    "\n",
    "    # Divide each exponent by the sum of the exponents and round to 3 decimal places\n",
    "    probabilities = [round(i / sum_of_exponents, 3) for i in exponents]\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "print(softmax([1.3, 5.1, 2.2, 0.7, 1.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadcb387-7b30-47bb-b631-9edd380ecb92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02019046 0.90253769 0.04966053 0.01108076 0.01653055]\n"
     ]
    }
   ],
   "source": [
    "# Define the output layer values (logits)\n",
    "logits = np.array([1.3, 5.1, 2.2, 0.7, 1.1])\n",
    "\n",
    "# Implement the softmax function\n",
    "def softmax(i):\n",
    "    exp_i = np.exp(i) # Compute the exponentials of the input values\n",
    "    return exp_i / np.sum(exp_i) # Normalize by dividing by the sum of exponentials\n",
    "\n",
    "# Apply the softmax function\n",
    "probabilities = softmax(logits)\n",
    "\n",
    "# Print the resulting probabilities\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69d33b-2937-4052-ae7d-b18088a58817",
   "metadata": {},
   "source": [
    "## Self Attention vs Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7df841-2852-4b8d-914e-445c4aaebddd",
   "metadata": {},
   "source": [
    "- Self-attention: The fundamental building block of transformer-based LLMs that allows models to weigh the importance of different parts of the input data.\n",
    "- Multi-head attention: An extension of self-attention that allows the model to simultaneously focus on information from different representation subspaces.\n",
    "- Cross-attention: A variant that enables the model to attend to two different sequences, which makes it useful in tasks like translation or summarization.\n",
    "- Causal-attention: A variant to ensure that the prediction for each token depends only on the preceding tokens, which is important for text generation, where each prediction should be based only on the prior context.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
